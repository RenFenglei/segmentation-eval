\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref} %url
\usepackage{comment}
%\usepackage[caption=false]{subfig}
\input{config/headers}
\input{config/colors}


\ifCLASSOPTIONcompsoc
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\else
\usepackage[caption=false,font=footnotesize]{subfig}
\fi

\usetikzlibrary{external}
\tikzexternalize[prefix=tikz/]
\tikzexternalize[prefix=tikz/,shell escape=-enable-write18]
\tikzset{external/system call= {pdflatex %-save-size=80000 
%                           -pool-size=10000000 
 %                          -extra-mem-top=50000000 
 %                          -extra-mem-bot=10000000 
  %                         -main-memory=90000000 
                           \tikzexternalcheckshellescape 
                           -halt-on-error 
                           -interaction=nonstopmode %-shell-escape
                           -jobname "\image" "\texsource"}} 
                           
%\usepackage{todonotes}
\newcommand{\remSili}[1]{{\color{red}{\tiny [SG]} {\scriptsize #1}}}
\newcommand{\remSimi}[1]{{\color{yellow}{\tiny [SM]} {\scriptsize #1}}}
\newcommand{\remZeni}[1]{{\color{orange}{\tiny [Z]} {\scriptsize #1}}}
\newcommand{\remRaqi}[1]{{\color{magenta}{\tiny [R]} {\scriptsize #1}}}
\newcommand{\remEwai}[1]{{\color{violet}{\tiny [E]} {\scriptsize #1}}}
\newcommand{\remFeli}[1]{{\color{green}{\tiny [F]} {\scriptsize #1\par}}}
                              
\begin{document}

\title{Combining convolutional side-outputs for road image segmentation
\thanks{The authors are grateful to FAPEMIG (PPM 00006-16), CNPq (Universal 421521/2016-3 and PQ 307062/2016-3), CAPES (MAXIMUM STIC-AmSUD 048/14) and PUC Minas for the financial support to this work.}
}

\author{
\IEEEauthorblockN{
Felipe A. L. Reis\textsuperscript{\dag}, Raquel Almeida\textsuperscript{\dag}, Ewa Kijak\textsuperscript{*}, Simon Malinowski\textsuperscript{*},\\ Silvio Jamil F. Guimar\~aes\textsuperscript{\dag} and Zenilton K. G. do Patroc\'inio Jr.\textsuperscript{\dag}
}
\\
\IEEEauthorblockA{
\textsuperscript{\dag}\textit{Audio-Visual Information Processing Laboratory} -- \textit{Pontifical Catholic University of Minas Gerais} \\ 
Belo Horizonte, Minas Gerais, Brazil \\
\{falreis, raquel.almeida.685026\}@sga.pucminas.br, \{sjamil, zenilton\}@pucminas.br
\\ \\
\textsuperscript{*}\textit{Linkmedia} -- Univ Rennes, Inria, CNRS, IRISA\\
Rennes, France \\
\{ewa.kijak, simon.malinowski\}@irisa.fr
}
}

\maketitle

\begin{abstract}
Image segmentation consists in creating partitions within an image into meaningful areas and objects. It can be used in scene understanding and recognition, in fields like biology, medicine, robotics, satellite imaging, amongst others. In this work we take advantage of the learned model in a deep architecture, by extracting side-outputs at different layers of the network  for the task of image segmentation. We study the impact of the amount of side-outputs and evaluate strategies to combine them. A post-processing filtering based on mathematical morphology idempotent functions is also used in order to remove some undesirable noises. Experiments were performed on the publicly available KITTI Road Dataset for image segmentation. Our comparison shows that the use of multiples side outputs can increase the overall performance of the network, making it easier to train and more stable when compared with a single output in the end of the network. Also, for a small number of training epochs (500), we achieved a competitive performance when compared to the best algorithm in Kitti Evaluation Server.
\end{abstract}


\begin{IEEEkeywords}
convolutional neural network, CNN, image segmentation, mathematical morphology, region detection, side-outputs, merging strategies
\end{IEEEkeywords}

\input{files/intro}
%\input{files/deep-hier}
\input{files/related}
\input{files/method}
\input{files/experiments}
\input{files/conclusion}

%\newpage

\bibliographystyle{IEEEtran}
\bibliography{2019-ijcnn,dl,hier-seg}

\end{document}
