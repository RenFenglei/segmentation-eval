\section{Experiments}
\label{sec:experiments}

Experiments were conducted in the KITTI Road/Lane Dataset, part of KITTI Vision Benchmarking Suite~\cite{KITTI}. The dataset  contains  images for road and lane estimation for the task of image segmentation. It is consisted of 289 training and 290 test images. The ground-truth is manually annotated for two different road types: (i) road, road area composing all lanes; and (ii) lane, lane the vehicle is currently driving on. It is important to notice that the ground-truth is only available for training set and the test evaluation should be performed using KITTI Server.

In this work, it is used only the road ground-truths and the lane annotations were ignored. This dataset contains the same image with different ground-truths for lane and road estimation. Then, we prefer to use the road estimation and build the classifier on a binary problem~(road and background). The road type is divided in three different categories of road scenes, namely: (i) uu\_road, urban unmarked; (ii) um\_road, urban marked; and (ii) umm\_road, urban multiple marked lanes.  

To increase the number of images in the training set, it is performed some data augmentation procedures. The following techniques were made: pepper/salt noise, horizontal flipping (mirror), contrast change, brightness change, noise shadow and random rain/snow. Procedures that would create undesired behavior, such as the road in the sky and distortions that would change the nature of the objects in the scene, such as cars and pedestrians were avoided. Augmentation procedures resulted in 2601 images, divided in 2080 samples for training and 521 samples for validation (about 20\%). 


\subsection{Experimental setup}
   
Our networks were build using using Keras \cite{chollet2015keras} with Tensorflow \cite{tensorflow2015-whitepaper}. We used a pre-trained VGG16 model to initialize the weights. Also, we use SGD optimization with learning rate set to 1e-3, decay of 5e-6 and momentum of 0.95. The default batch size contains 16 images. All training experiments were performed in GeForce GTX 1080 8GB GPU.

For simplicity, in the remaining of this work, the network using the side outputs extracted at each stage of the VGG will be called Stage Layer Outputs~(\textbf{SLO}) and it is composed by $n=5$ side outputs. Similarly, for the side outputs extracted at each convolutional layer, it will be called All Layers Outputs~(\textbf{ALO}) and it is composed by $n=13$ side outputs. For comparison, it is also defined a network similar to VGG, with only the final output, without any side outputs, called No Side Outputs~(\textbf{NSO}).

The operations to combine side outputs are presented in the name of the methods. The merging operations \textbf{ADD}, \textbf{AVG} and \textbf{MAX} are available for both ALO and SLO methods. Once NSO does not contains side outputs, it does not contains merging strategies.

\subsection{Training results - Methods Comparison}

The first test set was design to identify the best neural network and its best merging methods. We train all nets with all merging methods for 100 epochs to determine which one learns faster and achieve the best result. This conduct lead us to understand how layers can be easily combined to produce outputs with good precision.

Figures \ref{fig:validation_loss}, \ref{fig:validation_accuracy} and \ref{fig:pixel_error} presents the relevant curves obtained during the training phase for the proposed approaches. 
Figure \ref{fig:validation_loss}, presents categorical cross-entropy loss curve for tested approaches. ALO networks appears to be more stable with a faster decay than NSO and all SLO approaches. Also, it is important to notice that NSO and SLO-MAX produces high instability in the learning course. In other hand, ALO-AVG presents the best result for the test, followed by ALO-MAX and ALO-ADD merging strategies.

\begin{figure*}
  \caption{Categorical Cross-Entropy Validation Accuracy and Pixel Error Validation Loss}
  \centering
  \begin{tabular}{ll}
    \includegraphics[width=1.\columnwidth]{figures/falreis/validation_accuracy.png}
    \label{fig:validation_accuracy}
    
    \includegraphics[width=1.\columnwidth]{figures/falreis/pixel_error.png}
    \label{fig:pixel_error}
  \end{tabular}
\end{figure*}

Figures \ref{fig:validation_accuracy} and \ref{fig:pixel_error} presents metrics to identify the best values. Figure \ref{fig:validation_accuracy} contains validation accuracy and is related to categorical cross entropy method while Figure \ref{fig:pixel_error} shows Fuse Pixel Error method. While Figure \ref{fig:validation_accuracy} shows an expected curve, after loss evaluation in the previous image, Figure \ref{fig:pixel_error} indicates a new information: SLO-MAX neural network seens to overfitting around 40 epochs. After some steps with unstable pixel error values, the values persists almost unchange for the rest of training epochs. 

From previous graphs, in short we have ALO networks with  superior and more desirable behavior than the SLO and NSO models. It is believed that these results are consequence of the considerably larger amount of side outputs, which create more possibilities of interchangeability between confidant values.

\subsection{Best results}

In order to improve the results, a new set of tests were performed using 500 training epochs. As some networks had a poor performance, we evaluated only the two-best nets in the previous test. The categorical cross entropy validation accuracy and pixel error validation loss, for both ALO-AVG and ALO-MAX nets are available in Figure \ref{fig:val_acc_500_epochs}.

The best accuracy value for ALO-AVG model was \textbf{0.9821} and the best fuse pixel error was \textbf{0.0332}. For ALO-MAX model, the best accuracy and fuse pixel error were \textbf{0.9823} and \textbf{0.0372}.

\begin{figure*}
  \caption{Validation Accuracy and Pixel Error for 500 epochs test set}
  \centering
  \begin{tabular}{ll}
    \includegraphics[width=1.\columnwidth]{figures/falreis/val_acc_500_epochs.png}
  
    \includegraphics[width=1.\columnwidth]{figures/falreis/pixel_error_500_epochs.png}
  \end{tabular}%
  \label{fig:val_acc_500_epochs}
\end{figure*}

\subsection{Post-processing using mathematical morphology}

After the training procedure, we create a post processing step to reduce possible noises in results proposition. For this, we used the mathematical morphology operation of Opening~\cite{najman13}. This procedure removes small noises created by the foreground~(the road) in the background. We defined a set of kernels with the sizes of $5\times5$, $7\times7$, $9\times9$, $11\times11$ and $13\times13$ and applied in the images to reduce different sizes of noises. 

For comparison, we developed Figure \ref{fig:post_processing_comp}. In this image, we selected an output result that clearly shows the benefits of mathematical morphology post processing. {\color{red}It is possible to see the removal of part of the noise in the right of the image.} This procedure increase the confidence, once small variations in the results can lead a potential problem, if used in a self-driving vehicle.

\begin{figure}
  \caption{Comparison between ALO-AVG without post processing and ALO-AVG with post-processing with mathematical morphology. {\color{red}Substituir imagem por uma com evidencia mais clara.}}
  \centering
  \includegraphics[width=0.9\columnwidth]{figures/falreis/post_processing_comparison.png}
  \label{fig:post_processing_comp}
\end{figure}

\subsection{Evaluation results and comparison with the state-of-the-art}

Reminding that the test evaluation could only be performed using KITTI Server, the metrics provided are maximum F1-measure~(MaxF), average precision~(AP), precision~(PRE), recall~(REC), false positive rate~(FPR) and false negative rate~(FNR). 

The server tests were performed using ALO-AVG method, the best one in the training process. To provide succint labels, we will use the name \textbf{ALO-AVG} for the regular approach and \textbf{ALO-AVG-MM} for the version with mathematical morphology post-processing. 

The results achieved  on the test set according to each category in the road scenes are presented in Table~\ref{tab:metrics}. As expected, the ALO-AVG-MM model performed better then the ALO-AVG in all almost all of the cases. {\color{red}It is also possible to notice that although the post-processing slightly improved the overall performance, it also increased the number of false negatives. This could be an indications that perhaps the applied kernel sizes are not adequate and are removing more of the foreground than the desired.}

If compared with the state-of-the-art~(called \textit{PLARD}, an anonymous submission on the KITTI Server platform), the proposed method is comparable and sometimes superior, regarding the maximum F1-measure and the recall metrics. This is due the fact that although the reported state-of-the-art on the dataset presents a superior average precision, it also almost always presents a higher rate of false positives an negatives. This indicates that the proposed methods are more precise in delineating the regions to be segmented.

\input{tables/kitti-metrics}

As a final and visual representation of the results, we presents in Figure \ref{fig:visual_representation}. This image shows the results marked (in green) over the road, to shows the performance of our model.

\begin{figure}
  \caption{Visual representation of the results}
  \centering
  \includegraphics[width=1.\columnwidth]{figures/falreis/visual_representation.png}
  \label{fig:visual_representation}
\end{figure}
