\section{Related work}
\label{sec:related}

Deep learning approaches were initially described as black-box methods, meaning that not much were known about the reasoning and decisions of the created models. Much effort has been made to investigate the networks operation, whether through methodical experimentation~\cite{ilin17,kuo16,eigen14,zhang17} or visualization methods~\cite{simonyan13,zeiler14}. Those efforts provided more clarity on the deep models and characterized the learned features as complex concepts build from simpler ones. Also they demonstrate the learning progression from detailed to coarser representations as the scale and resolution reduce through the convolutional neural network (CNN).  When applied to object recognition task for instance, the raw pixel on the input layer is learned as segments and parts, until the composition of an object concept on posterior layers, while the scale reduces to a single feature vector on the output.  

Recent works aim at taking advantage of the multi-scale representation naturally embedded in deep convolutional network, through the increasing of receptive fields as sub-sampling is applied, in high-level tasks. For the edge detection task in particular, three main architectures standout in recent years, namely: (i) Holistically-nested Edge Detection~(HED)~\cite{xie2015,xie2017}; (ii) Convolutional Oriented Boundaries~(COB)~\cite{maninis2017}; and (iii) Rich Convolutional Features~(RCF)~\cite{liu2017}. These architectures all extract side-outputs from a traditional CNN model, but each present a different strategy to combine them to achieve the edge-detection task.

The HED network creates a side-output layer generating boundary maps at each last convolutional layer of each stage of the VGG16 network~\cite{simonyan2014}. In HED, each side-output is associated with a classifier in a deeply supervised scheme~\cite{lee2015} for the task of edge detection. The combination of the side-ouput predictions is achieved by a fusion layer added to the network. This fusion layer learns the weights for each side-output that determine its contribution on the final evaluation.
The evaluation is performed by a cost-sensitive function to balance the bias towards non-edge pixels. The HED network significantly improved the performance for multiple datasets.

The authors in~\cite{cheng2016} use the edge maps created by the HED network alongside with other features such as brightness, color, gradient and variance to describe images. The goal is to create an efficient framework for real-time segmentation, focused on a fusion strategy to update region features.


In the COB network, the authors also create edge maps from the side activations, but the method mainly differs from HED in that the candidate contours are assigned an orientation information. It also generates region hierarchies by efficiently combining multiscale oriented contour detections. The network performs well in multiple tasks such as object proposal, object detection, semantic contour and segmentation.


Finally, in contrast to the HED network, RCF uses the CNN features of all the convolutional layers, arguing that this could create more detailed representations and improve the network accuracy. The side outputs from all convolutional layers of a same stage are combined using a series of operations such as $1\times1$ convolutions, element-wise sums, and up-sampling. The up-sampled feature maps of each stage are then concatenated and fused by a $1\times1$ convolution to produce the final prediction. The RCF network, not only creates multiple side-outputs, but also uses image pyramids during testing, presenting multiple scales of an image to the detector and averaging all the resulting edge probability maps to get a final prediction map. 

Motivated by the performance of these approaches, we want to understand in this work the influence of side-output for a segmentation task, that is where they should be extracted them and how to combine them to provide the more relevant information regarding the task.

