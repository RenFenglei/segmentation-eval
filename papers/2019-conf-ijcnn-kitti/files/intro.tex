\section{Introduction}
\label{sec:intro}

Image segmentation refers to the partition of an image into a set of regions representing  meaningful areas. It is considered a challenging semantic task, aiming to determine and group uniform regions for analysis. According to~\cite{DOMINGUEZ}, to create an adequate segmented image it is necessary that the output presents some fundamental characteristics, such as: (i) region uniformity and homogeneity in  its features, such as gray level, color or texture; (ii) region continuity, without holes; (iii) significant difference to adjacency regions; and (iv) spacial accuracy with smooth boundaries and without raggedness. 

Image segmentation is an active topic of research and in a typical approach the procedure could be divided in two stages~\cite{guigues06}: (i) low-level analysis, which evaluate the pixel characteristics, neighboring relation and it is ideally uncommitted in terms of position, orientation,
size and contrast; and (ii) high-level analysis, which maps the low-level characteristics to fulfill the task.  

Recently, the deep learning approach drastically changed the computational paradigm for visual tasks. The main advantage of deep learning algorithms is that it does not require an engineered model to operate, meaning that they are capable of learning not only the features to represent the data but also the models to describe it~\cite{goodfellow16}. Facing this new paradigm, researches initially replaced  hand-engineered features in the low-level analysis by the features learned in deep models~\cite{farabet2013,simonyan2014,lee2015}, which mostly achieve the desirable characteristics. More recently, there is many proposals exploring the learned model for the high-level analysis, creating maps from the outputs of different layers in a deep learning network~\cite{xie2017,cheng2016,maninis2017,liu2017}. 

One challenge on the latter strategy is how to combine the output from distinct layers, considering that they are presented with different sizes and could represent different concepts. In this work, it is presented strategies to combine the outputs from different layers, by using simple merging functions that explore useful behavior in the learning process. It is also studied the amount of combined outputs necessary to create a viable region proposition for the task of image segmentation. In addition, it is also presented a post-processing filtering step using mathematical morphology idempotent functions~\cite{najman13} to better cope with the fundamental characteristics of an ideal segmented image.  

The remainder of this work is organized as it follows:  In Section~\ref{sec:related} it is characterized the hierarchy of concepts in deep models related work exploring theses models for high-level tasks. In Section~\ref{sec:method} it is presented the reasoning and strategies proposed in this work. In Section~\ref{sec:experiments} it is presented the dataset description, the experimental setup and results for the experiments. And, finally, in Section~\ref{sec:conclusion} the conclusions are laid out.

