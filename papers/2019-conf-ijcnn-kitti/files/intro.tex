\section{Introduction}
\label{sec:intro}

Image segmentation corresponds to the partition of an image into a set of meaningful areas, and it is considered as a challenging semantic task, aiming to determine and group uniform regions for analysis~\cite{DOMINGUEZ}. According to~\cite{DOMINGUEZ}, a proper segmented image should present some fundamental characteristics, such as: (i) region uniformity and homogeneity in  its features, such as gray level, color or texture; (ii) region continuity, without holes; (iii) significant difference between adjacent regions; and (iv) spatial accuracy with smooth and well-defined boundaries. 

Image segmentation is still an active topic of research and, usually, it could be divided in two stages~\cite{guigues06}: (i) low-level analysis, which evaluates the pixel characteristics, neighboring relation and it is ideally uncommitted in terms of position, orientation, size and contrast; and (ii) high-level analysis, which maps the low-level characteristics to fulfill the task.  

Recently, deep learning approaches have drastically changed the computational paradigm for visual tasks. The main advantage of deep learning algorithms is that they do not require an engineered model to operate, meaning that they can not only learn the features to represent the data, but also the models to describe them~\cite{goodfellow16}. Facing this new paradigm, hand-crafted features used in the low-level analysis were first replaced by the features learned in deep models~\cite{farabet2013,simonyan2014,lee2015}, which mostly achieved the desirable results. More recently, many proposals explored the learned model for the high-level analysis, in order to create segmentation maps from the outputs of different layers of a deep network~\cite{xie2017,cheng2016,maninis2017,liu2017, Yang2018}. 
These outputs are network samples, which do not require architectural changes and are therefore often called \textit{side-outputs}. 
One challenge on the latter strategy is the combination of the side-outputs from distinct layers, considering that they have different sizes and could represent different aspects of the input.  

In this work, we propose some strategies to combine the side-outputs from different layers by using simple merging functions in order to explore useful behavior in the learning process. We also study the amount of combined side-outputs that is needed to create a viable region propositions. Moreover, we propose the use of a post-processing filtering based on mathematical morphology idempotent functions~\cite{najman13} in order to remove some undesirable small segments.

To evaluate our model, the networks were trained for a road image segmentation task. The goal is develop methods to improve Vision-based driver-assistance systems (VB-DAS), that become popular in modern vehicles. These systems aims to identify lane lines, provide blind spot supervision, and, recently, distinguish the road from different objects such pedestrians, sidewalks and other vehicles \cite{Saleem20018, Yang2018, Rezaei2017}. Road identification can also be used in road monitoring, traffic management and self-driving cars. In this context, providing a robust and reliable segmentation is essential.

%road mapping~\textbf{\cite{Parajuli2018,Bastani2018}}
 

The remainder of this work is organized as follows. In Section~\ref{sec:related}, related works that characterize the hierarchy of concepts in deep models are described. In Section~\ref{sec:method}, the proposed method and the merging strategies are presented. In Section~\ref{sec:experiments}, a quantitative and qualitative assessment are done. And, finally, in Section~\ref{sec:conclusion}, some conclusions are drawn.