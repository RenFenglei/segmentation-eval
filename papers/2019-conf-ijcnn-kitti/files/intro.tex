\section{Introduction}
\label{sec:intro}

Image segmentation refers to the partition of an image into a set of regions representing  meaningful areas, and it is considered as a challenging semantic task, aiming to determine and group uniform regions for analysis. According to~\cite{DOMINGUEZ}, an adequate segmented image should present some fundamental characteristics, such as: (i) region uniformity and homogeneity in  its features, such as gray level, color or texture; (ii) region continuity, without holes; (iii) significant difference between adjacent regions; and (iv) spatial accuracy with smooth boundaries and without raggedness. Image segmentation is still an active topic of research and, usually, it could be divided in two stages~\cite{guigues06}: (i) low-level analysis, which evaluate the pixel characteristics, neighboring relation and it is ideally uncommitted in terms of position, orientation, size and contrast; and (ii) high-level analysis, which maps the low-level characteristics to fulfill the task.  

Recently, deep learning approaches have drastically changed the computational paradigm for visual tasks. The main advantage of deep learning algorithms is that it does not require an engineered model to operate, meaning that they are capable of learning not only the features to represent the data but also the models to describe it~\cite{goodfellow16}. Facing this new paradigm, proposals initially replaced  hand-craft features in the low-level analysis by the features learned in deep models~\cite{farabet2013,simonyan2014,lee2015}, which mostly achieved the desirable results. More recently, many proposals explore the learned model for the high-level analysis, in order to create segmentation maps from the outputs of different layers from a deep network~\cite{xie2017,cheng2016,maninis2017,liu2017}. 

One challenge on the latter strategy is the combination of the output from distinct layers, considering that they have different sizes and could represent different aspects of the input. In this work, we propose some strategies to combine the outputs from different layers by using simple merging functions in order to explore useful behavior in the learning process. We also study the amount of combined side-outputs \remEwai{side-outputs should be defined} which are necessary to create a viable region proposition.

The networks are trained for a road image segmentation task. The goal in this application is to improve the performance of self-driving cars, aiming to distinguish the road from different objects such pedestrians, sidewalks and cars. Moreover, we propose the use of a post-processing filtering based on mathematical morphology idempotent functions~\cite{najman13} in order to remove some undesirable small segments.
%, more specifically,  an area opening mathematical morphology idempotent functions~\cite{najman13} to better cope with the fundamental characteristics of an ideal segmented image.  

The remainder of this work is organized as follows. In Section~\ref{sec:related}, related works that characterize the hierarchy of concepts in deep models are described. In Section~\ref{sec:method}, the proposed method and the merging strategies are presented. In Section~\ref{sec:experiments}, a quantitative and qualitative assessment are done. And, finally, in Section~\ref{sec:conclusion}, some conclusions are drawn.

