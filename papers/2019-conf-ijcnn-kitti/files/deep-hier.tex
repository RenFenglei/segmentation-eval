\section{Hierarchies in deep models}
\label{sec:deep-hier}

Deep learning approaches were initially described as black-box methods, meaning that not much were known about the reasoning and decisions of the created models. Much exertion have been applied to investigate the networks operation, whether by methodical experimentation~\cite{ilin17,kuo16,eigen14,zhang17} or visualization methods~\cite{simonyan13,zeiler14}. Those efforts provided more clarity of the hierarchical aspects of the deep features, which allowed researches to explore these aspects in their endeavors. The  hierarchies learned in deep models are categorized as complex concepts build from simpler ones. When applied for object recognition task for instance, the raw pixel on the input layer is learned as segments and parts until the composition of an object concept at the final layer.  

These hierarchies could be particularly observed in convolutional networks, which are a stacked composition of three main layers, namely: (i) convolution; (ii) pooling; and (iii) non-linear activation. In \cite{ilin17} the authors directly assessed the hierarchy of concepts in convolutional networks, analyzing the knowledge representation and the network abstraction at each type of layer.  The authors are capable to demonstrate the generic aspect at earlier stages and the specialization at later layers. The findings are conformed with the expected behavior of convolutional networks, but it is possible to observe that most of the learned abstraction is due the convolutional layers and that the pooling and non-linear layers rarely contribute for increasing  the abstraction level.

